{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Pipeline\n",
    "\n",
    "A data preprocessing pipeline is a systematic and automated approach that integrates multiple preprocessing steps into a cohesive workflow. It serves as a guide for data professionals, outlining the necessary transformations and calculations required to clean and prepare data for analysis. Such pipelines are invaluable for data engineers, data analysts, data scientists, and machine learning engineers, as they automate repetitive preprocessing tasks, enabling professionals to focus on higher-value activities and improving overall workflow efficiency.\n",
    "\n",
    "The pipeline is composed of interconnected steps, each responsible for a specific task, such as:\n",
    "\n",
    "- **Imputing Missing Values**: Filling in gaps in the data to maintain consistency.\n",
    "- **Scaling Numeric Features**: Standardizing numerical variables to ensure uniformity across features.\n",
    "- **Encoding Categorical Variables**: Transforming categorical data into a format suitable for analysis or machine learning models.\n",
    "- **Detecting and Handling Outliers**: Identifying and addressing anomalies that could skew results.\n",
    "\n",
    "By adhering to a predefined sequence of operations, the pipeline ensures consistency, reproducibility, and efficiency throughout the preprocessing process. The steps mentioned above represent fundamental functions that every pipeline should perform when preparing any dataset for analysis or modeling.\n",
    "\n",
    "Here's how to create a Data Preprocessing pipeline using Python based on the fundamental functions that every pipeline should perform while preprocessing any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing_pipeline(data):\n",
    "    numeric_features = data.select_dtypes(include=['float', 'int']).columns\n",
    "    categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Handle missing values numerical features (Mean values)\n",
    "    data[numeric_features] = data[numeric_features].fillna(data[numeric_features].mean())\n",
    "\n",
    "    # Detect and handle outliers in numeric features using IQR\n",
    "    for feature in numeric_features:\n",
    "        Q1 = data[feature].quantile(0.25)\n",
    "        Q3 = data[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "        data[feature] = np.where((data[feature] < lower_bound) | (data[feature] > upper_bound),\n",
    "                                 data[feature].mean(), data[feature])\n",
    "        \n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[numeric_features])\n",
    "    data[numeric_features] = scaler.transform(data[numeric_features])\n",
    "\n",
    "    # Handle missing values in categorical features\n",
    "    data[categorical_features] = data[categorical_features].fillna(data[categorical_features].mode().iloc[0])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our basic data preprocessing pipeline is ready, we can go ahead and test it on a sample data and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n",
      "   NumericFeature1  NumericFeature2 CategoricalFeature\n",
      "0              1.0                7                  A\n",
      "1              2.0                8                  B\n",
      "2              NaN                9                NaN\n",
      "3              4.0               10                  A\n",
      "4              5.0               11                  B\n",
      "5              6.0               50                  C\n"
     ]
    }
   ],
   "source": [
    "# Load sample data\n",
    "df = pd.read_csv('data.csv')\n",
    "print('Original Data')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data:\n",
      "   NumericFeature1  NumericFeature2 CategoricalFeature\n",
      "0        -1.535624        -1.099370                  A\n",
      "1        -0.944999        -0.749128                  B\n",
      "2         0.000000        -0.398886                  A\n",
      "3         0.236250        -0.048645                  A\n",
      "4         0.826874         0.301597                  B\n",
      "5         1.417499         1.994431                  C\n"
     ]
    }
   ],
   "source": [
    "# Perform data preprocessing with pipeline\n",
    "clean_data = data_preprocessing_pipeline(df)\n",
    "\n",
    "print(\"Processed Data:\")\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can see there's a difference between the two datasets. The second output has undergone the outlined preprocessing steps within our pipeline. This process simplifies the process of cleaning and preparing data in addition to eliminating repetitions and integrating everything into one code. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
